import numpy as np
import tensorflow as tf

def rotate(x, y, z):
    """
    Make a 3-D rotation matrix to rotate [x] degree around x-axis, [y]
    degree around y-axis, and [z] degree around z-axis.
    Args:
        x   float   radius rotation around x-axis
        y   float   radius rotation around y-axis
        z   float   radius rotation around z-axis 
    Returns:
        R_x(x) * R_y(y) * R_z(z)
    """
    R_x = tf.stack([
            [1.,            0.,         0.],
            [0.,     tf.cos(x), -tf.sin(x)],
            [0.,     tf.sin(x),  tf.cos(x)]
        ])

    R_y = tf.stack([
            [tf.cos(y),     0.,     tf.sin(y)],
            [0.,            1.,            0.],
            [-tf.sin(y),    0.,     tf.cos(y)]
        ])

    R_z = tf.stack([
            [tf.cos(z), -tf.sin(z), 0.],
            [tf.sin(z),  tf.cos(z), 0.],
            [0.,                0., 1.]
        ])

    # Note: in tensorflow, we use x*R, but the ground truth is generated by R*x in numpy.
    # Since in numpy, y = R*x = R_z*R_x*R_y*x, so we want y = x*R = x*R_y*R_x*R_z = x*R
    return tf.matmul(R_y, tf.matmul(R_x, R_z))

def rotate_grid(vg, vp, size=32, rotation_axis='X', viewpoints=10,
                rx_range=[-20., 40.], ry_range=[0., 360.], rz_range=[0., 0.],
                verbose=0):
    vg = tf.reshape(vg, tf.stack([tf.shape(vg)[0], size, size, size]))
    nx, ny, nz = tf.shape(vg)[1], tf.shape(vg)[2], tf.shape(vg)[3]
    x_range = tf.range(-size/2, size/2, 1)
    y_range = tf.range(-size/2, size/2, 1)
    z_range = tf.range(-size/2, size/2, 1)
    pos_x, pos_y, pos_z= tf.meshgrid(x_range, y_range, z_range)
    grid = tf.cast(tf.stack([
        tf.reshape(pos_x, [-1]), tf.reshape(pos_y, [-1]), tf.reshape(pos_z, [-1])],
        axis=1), tf.float32)

    output_vg = []
    vgs = tf.unstack(vg, axis=0)
    view_points = tf.unstack(vp, axis=0)
    assert len(vgs) == len(view_points)

    batch = 0
    for i, (curr_vg, curr_z) in enumerate(zip(vgs, view_points)):
        batch+=1

        # Add domain specific knowledges to it
        if rotation_axis == 'X':
            rotation_angle = tf.floor((curr_z + 1.) * viewpoints / 2.) * 2 * np.pi / viewpoints
            rotation = rotate(rotation_angle, 0., 0.)
        elif rotation_axis == 'Y':
            rotation_angle = tf.floor((curr_z + 1.) * viewpoints / 2.) * 2 * np.pi / viewpoints
            rotation = rotate(0., rotation_angle, 0.)
        elif rotation_axis == 'Z':
            rotation_angle = tf.floor((curr_z + 1.) * viewpoints / 2.) * 2 * np.pi / viewpoints
            rotation = rotate(0., 0., rotation_angle)
        elif rotation_axis == 'XYZ':
            rx_angle = curr_z[0] / 180. * np.pi
            ry_angle = curr_z[1] / 180. * np.pi
            rz_angle = curr_z[2] / 180. * np.pi
            rotation = rotate(rx_angle, ry_angle, rz_angle)
        elif rotation_axis == 'PTN': # PTN rotation setting
            # put into degree
            ry_angle = ry_idx * (ry_range[1] - ry_range[0]) / float(viewpoints) + ry_range[0]

            # put into index
            step = (ry_range[1] - ry_range[0]) / viewpoints
            ry_idx = tf.floor((curr_z[1] - ry_range[0])/step)
            # Back to degree
            ry_angle = ry_idx * step + ry_range[0]

            rx_angle = rx_angle / 180. * np.pi
            ry_angle = ry_angle / 180. * np.pi
            rz_angle = rz_angle / 180. * np.pi
            rotation = rotate(rx_angle, ry_angle, rz_angle)
        else:
            raise Exception("Invalide rotation axis: %s"%rotation_axis)

        target_grid = tf.cast(tf.floor(tf.matmul(grid, rotation)), tf.int32)
        x_oob = tf.logical_or(tf.less(target_grid[:,0],  tf.cast(-nx/2, tf.int32)),
                              tf.greater_equal(target_grid[:,0],  tf.cast(nx/2, tf.int32)))
        y_oob = tf.logical_or(tf.less(target_grid[:,1],  tf.cast(-ny/2, tf.int32)),
                              tf.greater_equal(target_grid[:,1],  tf.cast(ny/2, tf.int32)))
        z_oob = tf.logical_or(tf.less(target_grid[:,2],  tf.cast(-nz/2, tf.int32)),
                              tf.greater_equal(target_grid[:,2],  tf.cast(nz/2, tf.int32)))
        xyz_inbound = tf.cast(
                tf.logical_not(tf.logical_or(x_oob, tf.logical_or(y_oob, z_oob))),
                tf.float32
            )

        # Create index bounds, TODO: assume square
        idx_lower_bound = tf.cast(tf.scalar_mul(
            tf.cast(tf.constant(-size/2), tf.float32),
            tf.ones(tf.shape(target_grid))
        ), tf.int32)
        idx_upper_bound = tf.cast(tf.scalar_mul(
            tf.cast(tf.constant(size/2-1), tf.float32),
            tf.ones(tf.shape(target_grid))
        ), tf.int32)
        target_grid_inbound = tf.maximum(idx_lower_bound, target_grid)
        target_grid_inbound = tf.minimum(idx_upper_bound, target_grid_inbound)
        target_grid_inbound = tf.cast(target_grid_inbound, tf.int32)
        target_grid_inbound = tf.add(target_grid_inbound,
            tf.cast(tf.scalar_mul(
                tf.cast(tf.constant(size/2), tf.float32),
                tf.ones(tf.shape(target_grid))
            ), tf.int32)
        )
        gathered = tf.gather_nd(curr_vg, target_grid_inbound)

        if verbose > 0:
            tf.summary.histogram("grid_%d_x"%i, target_grid_inbound[:,0])
            tf.summary.histogram("grid_%d_y"%i, target_grid_inbound[:,1])
            tf.summary.histogram("grid_%d_z"%i, target_grid_inbound[:,2])
            tf.summary.histogram("gathered_%d"%i, gathered)

        masked = tf.multiply(gathered, xyz_inbound)
        output_vg.append(tf.reshape(masked, tf.stack([nx, ny, nz])))
    rotated = tf.stack(output_vg)
    return rotated

def projection_orthographic(rotated, size=32, temperature=1.):
    print(rotated.get_shape())
    output_imgs = 1 - tf.exp(-tf.reduce_sum(rotated, 3)*temperature)
    output_imgs = tf.reshape(output_imgs, tf.stack([
        rotated.get_shape()[0], 32, 32, 1]))
    return output_imgs

def orthographic_coor(n=32, out_size=32):
    r = out_size / float(n)
    return [[np.array([np.array([int(x/r), int(y/r), z]) \
            for z in range(out_size)]) \
            for y in range(out_size)]  \
            for x in range(out_size)]

def np_pers_coor(vox, s=1, d=1, f=1, out_size=32):
    """
    Args:
        [vox]       (np.array [n]x[n]x[n])          Voxel grid
        [s]         (float)    The size of each voxel
        [d]         (float)    The distance from camera center to the first grid
        [p]         (float)    The size of a pixel in the projection plane
        [f]         (float)    Focal length.
        [out_size]  (int)      The size of the output image.
    Assumption:
        1. assuming that projection plane is always in z=1
    Rets:
        [ret]    (list(list(list([x,y,z]))))
                 ret[x][y] -> [(x_1,y_1,z_1), ..., (x_n,y_n,z_n)]
    """
    n = vox.shape[0]
    p = n*s/float(d)/float(out_size)
    pp_lower_x = (-n/2)*s/float(d)
    pp_lower_y = (-n/2)*s/float(d)
    print("P:%.5f"%p)
    ret = [[list() for _ in range(out_size)] for _ in range(out_size)]
    reverse_mapping = [[[list() for _ in range(n)] for _ in range(n)] for _ in range(n)]
    for l in range(n): # l is the depth in the voxel level
        z = d + l*s
        for x in range(n):
            for y in range(n):
                x_c = x*s - n/2
                y_c = y*s - n/2
                lower_x = int(np.floor((x_c/float(z) - pp_lower_x)/float(p)))
                upper_x = int(np.floor(((x_c+s)/float(z) - pp_lower_x)/float(p)))
                lower_y = int(np.floor((y_c/float(z) - pp_lower_y)/float(p)))
                upper_y = int(np.floor(((y_c+s)/float(z) - pp_lower_y)/float(p)))
                has_skip = True
                for x_p in range(lower_x, upper_x):
                    for y_p in range(lower_y, upper_y):
                        has_skip = False
                        ret[x_p][y_p].append(np.array([x,y,l]))
                        reverse_mapping[x][y][l].append(np.array([x_p, y_p]))
                if has_skip:
                    ret[lower_x][lower_y].append(np.array([x,y,l]))
    for x_p in range(len(ret)):
        for y_p in range(len(ret[x_p])):
            ret[x_p][y_p] = np.array(ret[x_p][y_p])
    return ret, reverse_mapping

def perspective_coor(n=32, s=1, d=1, f=1, out_size=32):
    """
    Args:
        [n]         (int)      Size of the voxel grid
        [s]         (float)    The size of each voxel
        [d]         (float)    The distance from camera center to the first grid
        [p]         (float)    The size of a pixel in the projection plane
        [f]         (float)    Focal length.
        [out_size]  (int)      The size of the output image.
    Assumption:
        1. assuming that projection plane is always in z=1
    Rets:
        [ret]    (list(list(list([x,y,z]))))
                 ret[x][y] -> [(x_1,y_1,z_1), ..., (x_n,y_n,z_n)]
    """
    ret, _ = np_pers_coor(np.zeros((n,n,n)), s=s, d=d, f=f, out_size=out_size)
    return ret

def coor_to_coormask(coor_array, batch_size):
    n = len(coor_array)
    max_len = max([len(coor_array[i][j]) for i in range(n) for j in range(n)])
    coor = np.zeros((batch_size, n, n, max_len, 4))
    mask = np.zeros((batch_size, n, n, max_len))
    for b in range(batch_size):
        for i in range(n):
            for j in range(n):
                for k, c in enumerate(coor_array[i][j]):
                    coor[b, i, j, k, :] = np.array([b, c[0], c[1], c[2]])
                    mask[b, i, j, k]    = 1
    return coor, mask

# NOTE: this works reasonably well, permutation too sow :(
def project_perspective(vg, coor_array, batch_size=128, size=32, temperature=1.,
        projector_pooling='exp', verbose=0):
    """
    Args:
        [vg]    (np.array [b]x[n]x[n]x[n])      Voxel grid
        [coor]  (list(list(list([x,y,z]))))     The coordinate of the perspective projection
    Rets:
        [img]   (np.array [b]x[n]x[n])              Projected image
    """
    print("Input shape:%s"%vg.get_shape())
    vg_t = tf.transpose(vg, perm=[1, 2, 3, 0])
    print("Permuted shape:%s"%vg_t.get_shape())

    coor, mask = coor_to_coormask(coor_array, 1)
    mask_batch = mask.astype(np.int)[0, ..., np.newaxis]
    coor_batch = coor.astype(np.int)[0, ..., 1:]
    print("Maskbatch:" + str(mask_batch.shape))
    print("Coorbatch:" + str(coor_batch.shape))

    gathered = tf.gather_nd(vg_t, coor_batch)
    print("Gathered : %s"% gathered.get_shape())

    gathered = gathered * mask_batch
    print("Maksed   : %s"% gathered.get_shape())

    gathered = tf.transpose(gathered, perm=[3, 0, 1, 2])

    if projector_pooling == 'exp':
        pooled = 1 - tf.exp(-tf.reduce_sum(gathered, axis=-1)*temperature)
    elif projector_pooling == 'max':
        pooled = tf.reduce_max(gathered, axis=-1)
    elif projector_pooling == 'avg':
        pooled = tf.reduce_mean(gathered, axis=-1)
    else:
        raise Exception("Invalid pooling type : %s"%projector_pooling)
    print("Pooled   : %s"%pooled.get_shape())

    return pooled


# NOTE: this works reasonably well, fast, but graph is large
def project_perspective_fast(
        vg, mask_batch, coor_batch, batch_size=128, size=32, temperature=1.,
        projector_pooling='exp', verbose=0
    ):
    """
    Args:
        [vg]    (np.array [b]x[n]x[n]x[n])      Voxel grid
        [coor]  (list(list(list([x,y,z]))))     The coordinate of the perspective projection
    Rets:
        [img]   (np.array [b]x[n]x[n])              Projected image
    """
    gathered = tf.gather_nd(vg, coor_batch)
    print("Gathered : %s"% gathered.get_shape())

    gathered = gathered * mask_batch
    print("Maksed   : %s"% gathered.get_shape())

    if projector_pooling == 'exp':
        pooled = 1 - tf.exp(-tf.reduce_sum(gathered, axis=-1)*temperature)
    elif projector_pooling == 'max':
        pooled = tf.reduce_max(gathered, axis=-1)
    elif projector_pooling == 'avg':
        pooled = tf.reduce_mean(gathered, axis=-1)
    else:
        raise Exception("Invalid pooling type : %s"%projector_pooling)
    print("Pooled   : %s"%pooled.get_shape())

    return pooled


class TFProjector(object):

    def __init__(self, cfg, verbose=0):
        self.vox_size = cfg.vox_size
        self.rotation_axis = cfg.rotation_axis
        self.viewpoints = cfg.viewpoints
        self.rx_range = cfg.rx_range
        self.ry_range = cfg.ry_range
        self.rz_range = cfg.rz_range
        self.projection_typ=cfg.projection_typ
        self.batch_size = cfg.batch_size
        self.resolution = cfg.resolution
        self.projector_pooling = cfg.pooling_typ
        self.temperature = cfg.projection_temperature
        self.verbose  = verbose
        self.distance = cfg.distance

        if self.projection_typ == 'orthographic':
            self.coor = orthographic_coor(n=self.vox_size, out_size=self.resolution)
        elif self.projection_typ == 'perspective':
            self.coor = perspective_coor(
                    n=self.vox_size, s=1, d=self.distance, out_size=self.resolution)
        elif self.projection_typ == 'perspective_fast':
            self.coor = perspective_coor(
                    n=self.vox_size, s=1, d=self.distance, out_size=self.resolution)
            coor, mask = coor_to_coormask(self.coor, self.batch_size)
            self.mask_batch = mask.astype(np.int)
            self.coor_batch = coor.astype(np.int)
            print("Maskbatch:" + str(self.mask_batch.shape))
            print("Coorbatch:" + str(self.coor_batch.shape))
        else:
            self.coor = None

    def __call__(self, vox, vp):
        print("Building projection generator...")
        print("\tRotation axis=%s..."%self.rotation_axis)
        print("\tNumber of viewpoints=%s..."%self.viewpoints)
        print("\tBatch size:%s"%self.batch_size)
        print("\tProjection Tyoe:%s"%self.projection_typ)
        print("\tTemperature:%s"%self.temperature)
        print("\tResolution:%s"%self.resolution)
        print("\tPooling type:%s"%self.projector_pooling)

        rotated = rotate_grid(
            vox, vp, rotation_axis=self.rotation_axis, viewpoints=self.viewpoints,
            rx_range=self.rx_range, ry_range=self.ry_range, rz_range=self.rz_range
        )

        if self.projection_typ in ['orthographic', 'perspective']:
            p = project_perspective(
                    rotated, self.coor, batch_size=self.batch_size,
                    size=self.resolution, projector_pooling=self.projector_pooling,
                    temperature=self.temperature, verbose=0)
            p = tf.expand_dims(p, -1)
        elif self.projection_typ == 'perspective_fast':
            p = project_perspective_fast(
                    rotated, self.mask_batch, self.coor_batch, batch_size=self.batch_size,
                    size=self.resolution, projector_pooling=self.projector_pooling,
                    temperature=self.temperature, verbose=0)
            p = tf.expand_dims(p, -1)
        elif self.projection_typ == 'orthographic_fast':
            p = projection_orthographic(
                    rotated, size=self.vox_size, temperature=self.temperature)
            print("Orthographic projection shape:%s"%p.get_shape())
        else:
            raise Exception("Invalid projector type:%s"%self.projection_typ)

        return p


